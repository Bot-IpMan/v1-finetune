## Compose specification version is omitted to use the latest syntax.

services:
  finetune:
    build:
      context: .
    volumes:
      - ./data:/app/data
      - /mnt/sdb/data/ai/models/model_output:/app/model_output
    environment:
      - PYTHONUNBUFFERED=1
    # Train the model on the included sample data.  After training the container
    # exits allowing dependent services to start.  You can override this
    # command when running compose if you wish to customise the training.
    # Use list form for command to avoid shell parsing issues.  This will
    # fineâ€‘tune the model on the provided sample dataset.  Modify or override
    # these arguments to point at your own training data.  The command below
    # downloads the base model from Hugging Face so the container requires
    # Internet access.
    command:
      - python
      - train.py
      - --base_model_name
      - Qwen/Qwen1.5-7B
      - --train_file
      - data/train.jsonl
      - --eval_file
      - data/eval.jsonl
      - --output_dir
      - /app/model_output
      - --use_lora
      - --num_epochs
      - "1"
      - --per_device_batch_size
      - "1"

  api:
    build:
      context: ./server
    volumes:
      - /mnt/sdb/data/ai/models/model_output:/app/model_output:ro
    environment:
      - MODEL_PATH=/app/model_output
    ports:
      - "8000:8000"
    depends_on:
      - finetune

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "8080:8080"
    environment:
      # Disable authentication for ease of use in local setups
      - WEBUI_AUTH=false
    volumes:
      - openwebui_data:/data
    depends_on:
      - finetune
      - api

volumes:
  openwebui_data: